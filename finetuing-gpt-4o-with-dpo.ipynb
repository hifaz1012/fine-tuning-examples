{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPO fine tuning with AOAI GPT-4o models\n",
    "\n",
    "Azure OpenAI lets developers customize OpenAI models with their own data and easily deploy their custom model using an easy to use and affordable managed service.\n",
    "\n",
    "While Fine Tuning can be a complex process, Azure OpenAI abstracts away a lot of the complexity to make fine tuning accessible to any developer.\n",
    "\n",
    "Direct Preference Optimization (DPO) fine-tuning allows you to adjust model weights based on human preferences with pairs of responses. It is faster than RLHF, while being equally effective at alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-requisites\n",
    "\n",
    "For this hands-on workshop, all you need is access to an Azure subscription and the ability to create Azure OpenAI resources and deployments. \n",
    "\n",
    "1. Install libs\n",
    "2. Create a GPT-4o deployment\n",
    "3. Create an Azure OpenAI resource in regions where gpt-4o-mini fine tuning is supported\n",
    "4. Create a `.env` file based on the [example.env](./example.env) file in this repository to store your credentials and important environment variables. Paste your AOAI endpoints, keys and deployment names, name the file `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q openai python-dotenv azure-ai-evaluation ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data\n",
    "\n",
    "Each example in your dataset should contain:\n",
    "- A prompt, like a user message.\n",
    "- A choosen output (an ideal assistant response).\n",
    "- A rejected output (a suboptimal assistant response).\n",
    "The data should be formatted in JSONL format, with each line representing an example in the following structure\n",
    "```json\n",
    "{  \n",
    "  \"input\": {  \n",
    "    \"messages\": {\"role\": \"system\", \"content\": ...},  \n",
    "    \"tools\": [...],  \n",
    "    \"parallel_tool_calls\": true  \n",
    "  },  \n",
    "  \"preferred_output\": [{\"role\": \"assistant\", \"content\": ...}],  \n",
    "  \"non_preferred_output\": [{\"role\": \"assistant\", \"content\": ...}]  \n",
    "}  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from typing import Dict, List, Any, Union, Optional\n",
    "\n",
    "## please prepare your env file, you can find example.env is an example file\n",
    "load_dotenv()\n",
    "aoai_endpoint = os.getenv(\"AOAI_FINETUNING_ENDPOINT\")\n",
    "aoai_api_key = os.getenv(\"AOAI_FINETUNING_API_KEY\")\n",
    "\n",
    "training_file_path = './data/training_data/train.jsonl'\n",
    "validation_file_path = './data/training_data/validation.jsonl'\n",
    "test_file_path = './data/training_data/test.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look at your prepared files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"input\": {\"messages\": [{\"role\": \"user\", \"content\": \"What are some effective strategies for learning chinese?\"}]}, \"preferred_output\": [{\"role\": \"assistant\", \"content\": \"To effectively learn a new language: 1) Set specific, achievable goals—whether that's conversational fluency or reading comprehension. 2) Practice consistently rather than cramming; even 20 minutes daily beats 2 hours once weekly. 3) Use spaced repetition systems (like Anki) to efficiently memorize vocabulary. 4) Focus on high-frequency words first; learning the 1,000 most common words typically covers 80% of everyday usage. 5) Immerse yourself through podcasts, YouTube videos, and shows in your target language—start with subtitles and gradually wean off them. 6) Find language exchange partners through apps like Tandem or HelloTalk for authentic conversation practice. 7) Make mistakes confidently; perfectionism slows progress. 8) Learn phrases rather than isolated words to understand natural speech patterns. 9) Connect emotionally with the language through music, films, or books you enjoy. 10) Track your progress with regular self-assessments to stay motivated.\"}], \"non_preferred_output\": [{\"role\": \"assistant\", \"content\": \"Download Duolingo and practice every day. Also watch some shows in that language and maybe get a phrasebook for when you travel there.\"}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        messages = [line for line in f]\n",
    "        for mes in messages:\n",
    "            print(mes)\n",
    "\n",
    "read_jsonl(validation_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Fine-tuning with DPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Uploading the training and validation data to Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "  azure_endpoint = aoai_endpoint,\n",
    "  api_key = aoai_api_key,\n",
    "  api_version = \"2025-02-01-preview\"  # This API version or later is required to access seed/events/checkpoint features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-4e2ddb4a63f346b7949cda7957cf238c\n",
      "Validation file ID: file-6da4001fdd3241ad8e73a26ae8c510b8\n"
     ]
    }
   ],
   "source": [
    "training_response = client.files.create(\n",
    "    file = open(training_file_path, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_path, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating the fine tuning job\n",
    "\n",
    "For each fine tuning job, you can specify the following hyperparameters:\n",
    "```json\n",
    "\"hyperparameters\": {\n",
    "    \"beta\": 0.1,\n",
    "    \"batch_size\": \"auto\",\n",
    "    \"learning_rate_multiplier\": \"auto\",\n",
    "    \"n_epochs\": \"auto\",\n",
    "}\n",
    "```\n",
    "\n",
    "- `beta`: \"auto\" or number, is a new option that is only available for DPO. It's a floating point number between 0 and 2 that controls how strictly the new model will adhere to its previous behavior, versus aligning with the provided preferences. A high number will be more conservative (favoring previous behavior), and a lower number will be more aggressive (favor the newly provided preferences more often).\n",
    "- `batch_size`: Number of examples in each batch. \n",
    "- `learning_rate_multiplier`: this will be used as the learning rate for the fine tuning job, as a multiple of the model's original learning rate. We recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best results\n",
    "- `epoch`:  The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\n",
    "\n",
    "The general recommendation is to initially train without specifying any of these, Azure OpenAI will pick a default for you based on dataset size, then adjusting based on results to find the ideal combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit fine-tuning training job\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    method={\n",
    "        \"type\": \"dpo\",\n",
    "        \"dpo\": {\n",
    "            \"hyperparameters\": {\"beta\": 0.1},\n",
    "        },\n",
    "    },\n",
    "    model = \"gpt-4o-2024-08-06\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters.\n",
    "    seed = 105 # seed parameter controls reproducibility of the fine-tuning job. If no seed is specified one will be generated automatically.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-78e4dae35cc34c719fe7e1350d546f3b\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-78e4dae35cc34c719fe7e1350d546f3b\",\n",
      "  \"created_at\": 1741712013,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": null,\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"seed\": 105,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-3e178c34b0894cc79b2126fd854b44fb\",\n",
      "  \"validation_file\": \"file-1e10645abfa1431d888c1642905ab9b4\",\n",
      "  \"estimated_finish\": 1741713850,\n",
      "  \"integrations\": null,\n",
      "  \"metadata\": null,\n",
      "  \"method\": {\n",
      "    \"dpo\": {\n",
      "      \"hyperparameters\": {\n",
      "        \"batch_size\": -1,\n",
      "        \"beta\": 0.1,\n",
      "        \"learning_rate_multiplier\": 1.0,\n",
      "        \"n_epochs\": -1,\n",
      "        \"l2_multiplier\": 0\n",
      "      }\n",
      "    },\n",
      "    \"supervised\": null,\n",
      "    \"type\": \"dpo\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Monitor the fine tuning job\n",
    "\n",
    "You can monitor your fine tuning job from this notebook or in the Azure OpenAI's new studio.\n",
    "\n",
    "In studio, you can go to Tools > Fine-tuning > Click on your job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also monitor the job from this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ftjob-78e4dae35cc34c719fe7e1350d546f3b finished with status: succeeded\n",
      "Checking other fine-tune jobs for this resource.\n",
      "Found 11 fine-tune jobs.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(5)\n",
    "\n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-78e4dae35cc34c719fe7e1350d546f3b\n",
      "Status: succeeded\n",
      "Trained Tokens: 26810\n"
     ]
    }
   ],
   "source": [
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed for file validation file.\n",
      "Job started.\n",
      "Training started.\n",
      "Created results file: file-a5c2a6d373ee4e8a90e47318b65db41a\n",
      "Step 1: training loss=0.5958462953567505\n",
      "Step 10: training loss=0.5675941109657288\n",
      "Step 20: training loss=0.5440755486488342\n",
      "Step 30: training loss=0.5091820955276489\n",
      "Step 40: training loss=0.47487473487854004\n",
      "Step 50: training loss=0.43927979469299316\n",
      "Step 60: training loss=0.41603386402130127\n",
      "Step 70: training loss=0.40014028549194336\n",
      "Step 80: training loss=0.3931383490562439\n",
      "Step 90: training loss=0.38585132360458374\n",
      "Step 100: training loss=0.3750596046447754\n",
      "Job succeeded.\n",
      "Postprocessing started.\n",
      "Completed results file: file-a5c2a6d373ee4e8a90e47318b65db41a\n",
      "Model Evaluation Passed.\n",
      "Training tokens billed: 20000\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: gpt-4o-2024-08-06.ft-78e4dae35cc34c719fe7e1350d546f3b\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None:\n",
    "    raise RuntimeError(\n",
    "        \"Fine-tuned model ID not found. Your job has likely not been completed yet.\"\n",
    "    )\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a new deployment with the fine tuned model\n",
    "\n",
    "When the fine-tuning job is done, it's time to deploy your customized model to make it available for use with completion calls. You can do it in the following two ways.\n",
    "\n",
    "### 4.1 From the notebook\n",
    "To create a new deployment from a notebook, you'll need an access token from Azure.\n",
    "1. Firstly, Open a terminal and run:\n",
    "2. Run login command: `az login`\n",
    "    - you can add `-t <your Microsoft Entra tenant>` if you have multiple tenants\n",
    "    - If it prompts to select a subscription id, you need to choose the right one to get login. or you can set subscription `az account set --subscription <name or id>`\n",
    "3. get your access token for the deployment by: `az account get-access-token`\n",
    "\n",
    "Paste the token `accessToken` in the below cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy fine-tuned model\n",
    "import requests\n",
    "\n",
    "token = \"<Paste Your Token>\"\n",
    "subscription = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "resource_group = os.getenv(\"AZURE_RESOURCE_GROUP_NAME\")\n",
    "resource_name = os.getenv(\"AZURE_RESOURCE_NAME\")\n",
    "\n",
    "aoai_endpoint = os.getenv(\"AOAI_FINETUNING_ENDPOINT\")\n",
    "aoai_api_key = os.getenv(\"AOAI_FINETUNING_API_KEY\")\n",
    "model_deployment_name = os.getenv(\"FINETUNED_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "deploy_params = {'api-version': \"2024-10-01\"}\n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 50},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model, #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would take minutes to have this model deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 From the studio\n",
    "\n",
    "On the fine tuning job page, click 'Deploy'\n",
    "\n",
    "![\"AOAI Deploy model\"](./static/dpo-model-deploy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Try your fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Chinese can be a rewarding but challenging endeavor. Here are some effective strategies to help you along the way:\n",
      "\n",
      "1. **Set Clear Goals**: Define why you want to learn Chinese and set specific, achievable goals. This could be anything from being able to hold a basic conversation to passing a proficiency exam.\n",
      "\n",
      "2. **Learn Pinyin**: Start with Pinyin, the Romanization of Chinese sounds, to help you with pronunciation and reading. Understanding Pinyin is crucial for learning how to pronounce words correctly.\n",
      "\n",
      "3. **Focus on Tones**: Chinese is a tonal language, so mastering the four tones (five if you include the neutral tone) is essential. Practice listening and repeating tones regularly.\n",
      "\n",
      "4. **Build a Strong Vocabulary**: Start with the most common words and phrases. Use flashcards, apps, or spaced repetition systems like Anki to help memorize vocabulary.\n",
      "\n",
      "5. **Practice Speaking**: Engage in conversation with native speakers as much as possible. Language exchange partners, tutors, or conversation groups can provide valuable speaking practice.\n",
      "\n",
      "6. **Immerse Yourself**: Surround yourself with the language through Chinese media such as movies, TV shows, music, and podcasts. This helps with listening skills and cultural understanding.\n",
      "\n",
      "7. **Use Language Apps**: Apps like Duolingo, HelloChinese, or Rosetta Stone can provide structured lessons and practice exercises.\n",
      "\n",
      "8. **Study Characters**: Learn the most common Chinese characters. Start with simplified characters if you're focusing on Mainland China, or traditional characters for Taiwan and Hong Kong.\n",
      "\n",
      "9. **Practice Writing**: Writing helps reinforce memory. Practice writing characters by hand to understand their structure and stroke order.\n",
      "\n",
      "10. **Take a Class**: Enroll in a language course, either online or in-person, to get structured learning and feedback from a teacher.\n",
      "\n",
      "11. **Join Online Communities**: Participate in forums or social media groups dedicated to learning Chinese. This can provide support, resources, and motivation.\n",
      "\n",
      "12. **Be Consistent**: Regular practice is key. Try to dedicate a specific amount of time each day to studying Chinese, even if it's just 15-30 minutes.\n",
      "\n",
      "13. **Use Mnemonics**: Create associations or stories to remember characters and vocabulary more easily.\n",
      "\n",
      "14. **Be Patient and Persistent**: Language learning is a long-term process. Celebrate small victories and stay motivated by tracking your progress.\n",
      "\n",
      "By combining these strategies, you can create a comprehensive and effective learning plan tailored to your\n"
     ]
    }
   ],
   "source": [
    "model_deployment_name = os.getenv(\"FINETUNED_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "test_messages = [{'content': 'You are a helpful recipe assistant. ',\n",
    "  'role': 'system'},\n",
    " {'content': 'What are some effective strategies for learning chinese?',\n",
    "  'role': 'user'}]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_deployment_name, messages=test_messages, temperature=0, max_tokens=500\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Evaluate model\n",
    "During evaluation, your model or application is tested with the given dataset. Use Azure AI Evaluation SDK to assess the performance of your generative AI applications. Generative AI application generations are quantitatively measured with mathematical based metrics, AI-assisted quality and safety metrics. Metrics are defined as `evaluators`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Load your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>preferred_output</th>\n",
       "      <th>non_preferred_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'messages': [{'role': 'user', 'content': 'Wri...</td>\n",
       "      <td>[{'role': 'assistant', 'content': 'To effectiv...</td>\n",
       "      <td>[{'role': 'assistant', 'content': 'Download Du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  {'messages': [{'role': 'user', 'content': 'Wri...   \n",
       "\n",
       "                                    preferred_output  \\\n",
       "0  [{'role': 'assistant', 'content': 'To effectiv...   \n",
       "\n",
       "                                non_preferred_output  \n",
       "0  [{'role': 'assistant', 'content': 'Download Du...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_json('./data/training_data/banking_test.jsonl', lines=True)\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the fine tuned gpt-4o model with gpt-4o base but you could switch the baseline model to any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# load_dotenv('my.env')\n",
    "# run the base and finetuned models through the dataset\n",
    "BASELINE_OPENAI_DEPLOYMENT = os.getenv(\"BASELINE_OPENAI_DEPLOYMENT\")\n",
    "BASELINE_OPENAI_ENDPOINT= os.getenv(\"BASELINE_OPENAI_ENDPOINT\")\n",
    "BASELINE_OPENAI_KEY=  os.getenv(\"BASELINE_OPENAI_KEY\")\n",
    "\n",
    "FINETUNED_OPENAI_DEPLOYMENT = os.getenv(\"FINETUNED_OPENAI_DEPLOYMENT\")\n",
    "FINETUNED_OPENAI_ENDPOINT = os.getenv(\"FINETUNED_OPENAI_ENDPOINT\")\n",
    "FINETUNED_OPENAI_KEY = os.getenv(\"FINETUNED_OPENAI_KEY\")\n",
    "\n",
    "baseline_client = AzureOpenAI(\n",
    "    azure_endpoint=BASELINE_OPENAI_ENDPOINT, \n",
    "    api_key=BASELINE_OPENAI_KEY,\n",
    "    api_version=\"2024-10-21\"\n",
    "    )\n",
    "\n",
    "finetuned_client = AzureOpenAI(\n",
    "    azure_endpoint=FINETUNED_OPENAI_ENDPOINT, \n",
    "    api_key=FINETUNED_OPENAI_KEY,\n",
    "    api_version=\"2024-10-21\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to generate texts from backend model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions\n",
    "def get_model_completions(client, input_messages, deployment):\n",
    "    \"\"\"\n",
    "    This function generates a model completion from a given prompt using the OpenAI API.\n",
    "\n",
    "    Parameters:\n",
    "    client (openai.Client): The AzureOpenAI client being used.\n",
    "    prompt (str): The prompt to be sent to the model for completion.\n",
    "    deployment (str): The identifier of the model deployment to be used for completion.\n",
    "\n",
    "    Returns:\n",
    "    str: The completed message content from the model. If an exception occurs during the process, it returns None and prints the exception.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(input_messages['messages'])\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "        messages=input_messages['messages'],\n",
    "        model=deployment,\n",
    "        temperature=0,\n",
    "    )\n",
    "    \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fc4f975388442a87a9d951165f610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Write a Poem on BlockChain?'}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cd9d2142ad4a7cad8c208c4e9d3314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Write a Poem on BlockChain?'}]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "test_df['baseline_model_response'] = test_df.progress_apply(lambda x: get_model_completions(baseline_client, x.input, BASELINE_OPENAI_DEPLOYMENT), axis=1)\n",
    "test_df['finetuned_model_response'] = test_df.progress_apply(lambda x: get_model_completions(finetuned_client, x.input, FINETUNED_OPENAI_DEPLOYMENT), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Define evaluation metrics\n",
    "\n",
    "This time we will use relevance evaluator to test \"relevance\" with a evaluation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevance': 5.0,\n",
       " 'gpt_relevance': 5.0,\n",
       " 'relevance_reason': 'The RESPONSE is a comprehensive poem that fully addresses the QUERY by providing a creative piece on Blockchain, along with additional insights into its significance and challenges.'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate, RelevanceEvaluator\n",
    "\n",
    "# AI assisted quality evaluator\n",
    "model_config = {\n",
    "    \"azure_endpoint\": BASELINE_OPENAI_ENDPOINT,\n",
    "    \"api_key\": BASELINE_OPENAI_KEY,\n",
    "    \"azure_deployment\": BASELINE_OPENAI_DEPLOYMENT,\n",
    "}\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "result = relevance_evaluator(\n",
    "    query=list(test_df['input'].tolist()[0]['messages'][0]['content']),\n",
    "    response=test_df['finetuned_model_response'].tolist()\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Also you can evaluate with your base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevance': 5.0,\n",
       " 'gpt_relevance': 5.0,\n",
       " 'relevance_reason': 'The RESPONSE is a comprehensive poem that fully addresses the QUERY by creatively exploring the concept of Blockchain, its features, and implications, providing additional insights.'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = relevance_evaluator(\n",
    "    query=list(test_df['input'].tolist()[0]['messages'][0]['content']),\n",
    "    response=test_df['baseline_model_response'].tolist()\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Within Azure AI Evaluators, you can try a comprehensive approach to evaluation includes three key dimensions:\n",
    "\n",
    "- Query and response: This scenario is designed for applications that involve sending in queries and generating responses, usually single-turn.\n",
    "- Retrieval augmented generation: This scenario is suitable for applications where the model engages in generation using a retrieval-augmented approach to extract information from your provided documents and generate detailed responses, usually multi-turn.\n",
    "- Custom evaluators: Tailored evaluation metrics can be designed to meet specific needs and goals, providing flexibility and precision in assessing unique aspects of AI-generated content. These custom evaluators allow for more detailed and specific analyses, addressing particular concerns or requirements that standard metrics might not cover.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Summary\n",
    "\n",
    "In this notebook, we've explored how to fine-tune GPT-4o using Direct Preference Optimization (DPO) on Azure OpenAI. DPO fine-tuning leverages preference-based data (chosen vs. rejected responses) to align model outputs more closely with user expectations. Azure OpenAI simplifies this process by abstracting away infrastructure complexities, providing developers with an accessible and cost-effective managed service for customizing and deploying advanced AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 8. Reference\n",
    "\n",
    "- [Azure OpenAI Service Documentation](https://learn.microsoft.com/azure/ai-services/openai/)\n",
    "- [Direct Preference Optimization (DPO) Paper](https://arxiv.org/abs/2305.18290)\n",
    "- [Fine-tuning Azure OpenAI models](https://learn.microsoft.com/azure/ai-services/openai/how-to/fine-tuning)\n",
    "- [Azure OpenAI Service Documentation](https://learn.microsoft.com/azure/ai-services/openai/)\n",
    "- [SFT AOAI Repo](https://github.com/Azure-Samples/azure-openai-raft.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
